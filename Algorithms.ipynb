{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import itertools\n",
    "import time\n",
    "import heapq\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from greedy_algo_for_searching import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def calculate_distance(point1, point2):\n",
    "    #return np.linalg.norm(point2 - point1)\n",
    "    #return math.sqrt((point2[0] - point1[0])**2 + (point2[1] - point1[1])**2)\n",
    "    # Convert RA and Dec from degrees to radians\n",
    "    ra1,dec1 = point1[0], point1[1]\n",
    "    ra2, dec2 = point2[0], point2[1]\n",
    "    ra1 = np.radians(ra1)\n",
    "    dec1 = np.radians(dec1)\n",
    "    ra2 = np.radians(ra2)\n",
    "    dec2 = np.radians(dec2)\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = ra2 - ra1\n",
    "    dlat = dec2 - dec1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(dec1) * np.cos(dec2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    # Calculate the angular distance (in radians)\n",
    "    distance = c\n",
    "\n",
    "    # Convert the angular distance from radians to degrees\n",
    "    distance_deg = np.degrees(distance)\n",
    "\n",
    "    return distance_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_probabilities(likelihoods):\n",
    "    total_likelihood = np.sum(likelihoods)\n",
    "    normalized_likelihoods = likelihoods / total_likelihood\n",
    "    return normalized_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_distance_to_time(cutoff_distance, rate_of_movement): #2000 per minute\n",
    "    if(cutoff_distance < 0):\n",
    "        return cutoff_distance\n",
    "    cutoff_time = cutoff_distance / rate_of_movement\n",
    "    return cutoff_time\n",
    "def convert_time_to_distance(cutoff_time, rate_of_movement): #2000 per minute\n",
    "    cutoff_distance = cutoff_time * rate_of_movement\n",
    "    return cutoff_distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_to_area(rate_mpm):\n",
    "    rate_mps = rate_mpm/60\n",
    "    time_seconds = 1000 / rate_mps\n",
    "    degrees_covered = 0.1 * time_seconds\n",
    "    area = degrees_covered ** 2\n",
    "    return area\n",
    "\n",
    "def area_to_rate(area):\n",
    "    degrees_covered = area ** 0.5\n",
    "    time_seconds = degrees_covered / 0.1\n",
    "    rate_mps = 1000 / time_seconds\n",
    "    rate_mpm = rate_mps*60\n",
    "    return rate_mpm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O(N^2) ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metric(probability, distance, n):\n",
    "    return probability / (distance ** n)\n",
    "\n",
    "def find_next_point_2(points, probabilities, current_point, path, n):\n",
    "    next_point_candidates = []\n",
    "    \n",
    "    for i,(point, probability) in enumerate(zip(points, probabilities)):\n",
    "\n",
    "        if tuple(point) not in path:\n",
    "            distance = calculate_distance(np.array(point),np.array(current_point))\n",
    "            metric = calculate_metric(probability, distance, n)\n",
    "            next_point_candidates.append((i, metric))\n",
    "    \n",
    "    next_point_candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    if next_point_candidates:\n",
    "        next_point = next_point_candidates[0][0]\n",
    "    else:\n",
    "        next_point = None\n",
    "    \n",
    "    return next_point\n",
    "\n",
    "def find_path_2(points, probabilities, n):\n",
    "    sorted_points_probs = sorted(zip(points, probabilities), key=lambda x: x[1], reverse=True)\n",
    "    sorted_points, sorted_probs = zip(*sorted_points_probs)\n",
    "    \n",
    "    start_point = sorted_points[0]\n",
    "    start_point_index = np.where(np.array(points) == start_point)[0][0]\n",
    "    index_path = [start_point_index]\n",
    "    current_point = start_point\n",
    "    point_path = [start_point]\n",
    "    point_path_set = {tuple(start_point)}\n",
    "    while len(index_path) < len(points):\n",
    "        next_point = find_next_point_2(points, probabilities, current_point, point_path_set, n)\n",
    "        \n",
    "        if next_point is None:\n",
    "            break\n",
    "        \n",
    "        index_path.append(next_point)\n",
    "        point_path.append(points[next_point])\n",
    "        point_path_set.add(tuple(points[next_point]))\n",
    "        current_point = points[next_point]\n",
    "    \n",
    "    return index_path,point_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paths_compounded2(points_arrays, likelihoods_arrays,n_s):\n",
    "    #n_s = np.linspace(n_min, n_max, num_algos)\n",
    "    \n",
    "    paths_compounded = []  # Initialize value2 as an empty list\n",
    "    index = range(len(points_arrays))\n",
    "    n_array = []\n",
    "    for i in index:\n",
    "        execution_times = []\n",
    "        array_values = []  # Initialize array_values for the current index\n",
    "        n_values = []\n",
    "        for n in n_s:\n",
    "            start_time = time.time()\n",
    "            points = points_arrays[i]\n",
    "            likelihoods = likelihoods_arrays[i]\n",
    "            #print(\"\\n n =\", n, \"\\n\")\n",
    "            n2 = n\n",
    "            n_values.append(n2)\n",
    "            v2,point_path = find_path_2(points, likelihoods, n)\n",
    "            array_values.append(v2)\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            execution_times.append(execution_time)\n",
    "        n_array.append(n_values)\n",
    "        paths_compounded.append(array_values)  # Append array_values to value2  \n",
    "        #print(execution_times)\n",
    "    return paths_compounded, n_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O(N) ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_next_point_1(sorted_points, sorted_probs, current_point, n):\n",
    "    point_1 = sorted_points[0]\n",
    "    prob_1 = sorted_probs[0]\n",
    "    \n",
    "    metric_1 = calculate_metric(prob_1, calculate_distance(np.array(point_1),np.array(current_point)), n)\n",
    "    \n",
    "    if len(sorted_points) > 1:\n",
    "        point_2 = sorted_points[1]\n",
    "        prob_2 = sorted_probs[1]\n",
    "        \n",
    "        metric_2 = calculate_metric(prob_2, calculate_distance(np.array(point_2), np.array(current_point)), n)\n",
    "        \n",
    "        if metric_1 >= metric_2:\n",
    "            next_point = point_1\n",
    "            sorted_points = sorted_points[1:]\n",
    "            sorted_probs = sorted_probs[1:]\n",
    "        else:\n",
    "            next_point = point_2\n",
    "            sorted_points = sorted_points[0:1] + sorted_points[2:]\n",
    "            sorted_probs = sorted_probs[0:1] + sorted_probs[2:]\n",
    "    else:\n",
    "        next_point = point_1\n",
    "        sorted_points = []\n",
    "        sorted_probs = []\n",
    "    \n",
    "    return next_point, sorted_points, sorted_probs\n",
    "\n",
    "def find_path_1(points, probabilities, n):\n",
    "    sorted_points_probs = sorted(zip(points, probabilities), key=lambda x: x[1], reverse=True)\n",
    "    sorted_points, sorted_probs = zip(*sorted_points_probs)\n",
    "    points = np.array(points)\n",
    "    probabilities = np.array(probabilities)\n",
    "    start_point = sorted_points[0]\n",
    "    sorted_points = sorted_points[1:]\n",
    "    sorted_probs = sorted_probs[1:]\n",
    "    index_path = [np.where(np.all(points == start_point, axis=1))[0][0]]\n",
    "    point_path = [start_point]\n",
    "    current_point = start_point\n",
    "    \n",
    "    while len(index_path) < len(points):\n",
    "        next_point, sorted_points, sorted_probs = find_next_point_1(sorted_points, sorted_probs, current_point, n)\n",
    "        \n",
    "        if next_point is None:\n",
    "            break\n",
    "        \n",
    "        next_point_index = np.where(np.all(points == next_point, axis=1))[0][0]\n",
    "        \n",
    "        index_path.append(next_point_index)\n",
    "        point_path.append(next_point)\n",
    "        current_point = next_point\n",
    "    \n",
    "    return index_path, point_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paths_compounded1(points_arrays, likelihoods_arrays,n_s):\n",
    "    #n_s = np.linspace(n_min, n_max, num_algos)\n",
    "    \n",
    "    paths_compounded = []  # Initialize value2 as an empty list\n",
    "    index = range(len(points_arrays))\n",
    "    n_array = []\n",
    "    for i in index:\n",
    "        execution_times = []\n",
    "        array_values = []  # Initialize array_values for the current index\n",
    "        n_values = []\n",
    "        for n in n_s:\n",
    "            start_time = time.time()\n",
    "            points = points_arrays[i]\n",
    "            likelihoods = likelihoods_arrays[i]\n",
    "            #print(\"\\n n =\", n, \"\\n\")\n",
    "            n2 = n\n",
    "            n_values.append(n2)\n",
    "            v2,point_path = find_path_1(points, likelihoods, n)\n",
    "            array_values.append(v2)\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            execution_times.append(execution_time)\n",
    "        n_array.append(n_values)\n",
    "        paths_compounded.append(array_values)  # Append array_values to value2\n",
    "        #print(execution_times)\n",
    "    return paths_compounded, n_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O(N!) ALGORITHM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_expected_value_1(points, path, likelihoods, n):\n",
    "    expected_value = 0.0\n",
    "    total_distance = 0.0\n",
    "    for i in range(len(path)):\n",
    "        if i == (len(path)-1):\n",
    "            expected_value += likelihoods[path[0]]\n",
    "        else:\n",
    "            current_point = points[path[i]]\n",
    "            next_point = points[path[i + 1]],\n",
    "            distance = calculate_distance(current_point, next_point)\n",
    "            total_distance = total_distance + distance\n",
    "            likelihood = likelihoods[path[i + 1]]  # Likelihood of the next point\n",
    "            expected_value += likelihood/(total_distance ** n)\n",
    "\n",
    "    return expected_value\n",
    "def generate_all_paths(points):\n",
    "    paths = []\n",
    "    total_points = len(points)\n",
    "    path_length = total_points\n",
    "\n",
    "    # Generate permutations of path indices\n",
    "    permutations = itertools.permutations(range(total_points), path_length)\n",
    "\n",
    "    # Convert permutations to paths\n",
    "    for perm in permutations:\n",
    "        path = [p for p in perm]\n",
    "        paths.append(path)\n",
    "\n",
    "    return paths\n",
    "\n",
    "def generate_plots_1(points_arrays, likelihoods_arrays, n):\n",
    "    for points, likelihoods in zip(points_arrays, likelihoods_arrays):\n",
    "        num_points = len(points)\n",
    "\n",
    "        # Generate all possible paths\n",
    "        all_paths = generate_all_paths(range(num_points))\n",
    "\n",
    "        max_expected_value = 0\n",
    "        max_path = None\n",
    "\n",
    "        # Calculate and compare the expected values for all paths\n",
    "        for path in all_paths:\n",
    "            expected_value = calculate_expected_value_1(points, path, likelihoods, n)\n",
    "            #print(\"Path:\", path)\n",
    "            #print(\"Expected Value:\", expected_value)\n",
    "            #print(\"---\")\n",
    "            if expected_value > max_expected_value:\n",
    "                max_expected_value = expected_value\n",
    "                max_path = path\n",
    "\n",
    "        # Print the maximum expected value and corresponding path\n",
    "        #print(\"Maximum Expected Value:\", max_expected_value)\n",
    "        #print(\"Corresponding Path:\", max_path)\n",
    "        # Plot the path with arrows\n",
    "        #plot_path_with_arrow(points, likelihoods, max_path)\n",
    "        return max_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paths_compounded(points_arrays, likelihoods_arrays,n_s):\n",
    "\n",
    "    value2 = []  # Initialize value2 as an empty list\n",
    "    index = range(len(points_arrays))\n",
    "    n_array = []\n",
    "    for i in index:\n",
    "        execution_times = []\n",
    "        array_values = []  # Initialize array_values for the current index\n",
    "        n_values = []\n",
    "        for n in n_s:\n",
    "            start_time = time.time()\n",
    "            points = [points_arrays[i]]\n",
    "            likelihoods = [likelihoods_arrays[i]]\n",
    "            #print(\"\\n n =\", n, \"\\n\")\n",
    "            n2 = n\n",
    "            n_values.append(n2)\n",
    "            v2 = generate_plots_1(points, likelihoods, n)\n",
    "            array_values.append(v2)\n",
    "            end_time = time.time()\n",
    "            execution_time = end_time - start_time\n",
    "            execution_times.append(execution_time)\n",
    "        n_array.append(n_values)\n",
    "        value2.append(array_values)  # Append array_values to value2\n",
    "    #print(execution_times)\n",
    "    return value2, n_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_probability_distribution(x, y, mean_x, mean_y, std_dev):\n",
    "    \"\"\"\n",
    "    Generates a Gaussian probability distribution as a function of x and y coordinates.\n",
    "    \"\"\"\n",
    "    exponent = -((x - mean_x)**2 + (y - mean_y)**2) / (2 * std_dev**2)\n",
    "    probability = np.exp(exponent) / (2 * np.pi * std_dev**2)\n",
    "    return probability\n",
    "\n",
    "def generate_points_array_likelihoods_array(num_galaxies_list, num_points_in_a_set, std_dev, grid_size=1000):\n",
    "    \"\"\"\n",
    "    Generates multiple sets of realizations, each with varying number of galaxies,\n",
    "    in a 10x10 grid and associates likelihood values using a Gaussian probability distribution.\n",
    "    \"\"\"\n",
    "    points_arrays = []\n",
    "    likelihoods_arrays = []\n",
    "    for num_galaxies in num_galaxies_list:\n",
    "        points_set = []\n",
    "        likelihoods_set = []\n",
    "        mean_x = np.random.uniform(0, grid_size)\n",
    "        mean_y = np.random.uniform(0, grid_size)\n",
    "\n",
    "        for _ in range(num_points_in_a_set):\n",
    "            # print(\"Mean x = \", mean_x)\n",
    "            # print(\"Mean y = \", mean_y)\n",
    "\n",
    "            points = np.random.uniform(0, grid_size, size=(num_galaxies, 2))\n",
    "            likelihoods = generate_probability_distribution(points[:, 0], points[:, 1], mean_x, mean_y, std_dev)\n",
    "            \n",
    "            likelihoods = normalize_probabilities([likelihoods])[0]\n",
    "            points_set.append(points)\n",
    "            likelihoods_set.append(likelihoods)\n",
    "        \n",
    "        points_arrays.append(points_set)\n",
    "        likelihoods_arrays.append(likelihoods_set)\n",
    "    return points_arrays, likelihoods_arrays\n",
    "\n",
    "# num_galaxies_list = [3, 4, 5]\n",
    "# num_points_in_a_set = 3\n",
    "\n",
    "# points_arrays, likelihoods_arrays = generate_points_array_likelihoods_array(num_galaxies_list, num_points_in_a_set)\n",
    "\n",
    "# print(\"points = \",points_arrays,\"\\nprobabilities = \",likelihoods_arrays,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def generate_probability_distribution(stellar_mass, peak_mass=1e9, std_dev=1e8):\n",
    "#     \"\"\"\n",
    "#     Generates a probability distribution based on stellar mass.\n",
    "#     \"\"\"\n",
    "#     # You can use any function here that maps stellar mass to probability\n",
    "#     # For example, a Gaussian centered at peak_mass\n",
    "#     exponent = -((stellar_mass - peak_mass)**2) / (2 * std_dev**2)\n",
    "#     probability = np.exp(exponent) / np.sqrt(2 * np.pi * std_dev**2)\n",
    "#     return probability\n",
    "\n",
    "# def generate_points_array_likelihoods_array(num_galaxies_list, num_points_in_a_set, peak_mass=1e9, std_dev=1e8, grid_size=1000):\n",
    "#     \"\"\"\n",
    "#     Generates multiple sets of realizations, each with varying number of galaxies,\n",
    "#     in a 10x10 grid and associates likelihood values based on stellar mass.\n",
    "#     \"\"\"\n",
    "#     points_arrays = []\n",
    "#     likelihoods_arrays = []\n",
    "    \n",
    "#     for num_galaxies in num_galaxies_list:\n",
    "#         points_set = []\n",
    "#         likelihoods_set = []\n",
    "\n",
    "#         for _ in range(num_points_in_a_set):\n",
    "#             # Generate random stellar masses (you can replace this with your actual data)\n",
    "#             # will be replaced by actual data\n",
    "#             stellar_masses = np.random.uniform(1e8, 1e10, size=num_galaxies)\n",
    "            \n",
    "#             # Calculate likelihoods based on stellar mass\n",
    "#             likelihoods = generate_probability_distribution(stellar_masses, peak_mass, std_dev)\n",
    "            \n",
    "#             # Normalize the likelihoods\n",
    "#             likelihoods = likelihoods / likelihoods.sum()\n",
    "            \n",
    "#             # Generate mock RA and Dec coordinates (x and y)\n",
    "#             # Will be replaced by actual data\n",
    "#             ra_dec_coordinates = np.random.uniform(0, grid_size, size=(num_galaxies, 2))\n",
    "            \n",
    "#             points_set.append(ra_dec_coordinates)\n",
    "#             likelihoods_set.append(likelihoods)\n",
    "        \n",
    "#         points_arrays.append(points_set)\n",
    "#         likelihoods_arrays.append(likelihoods_set)\n",
    "    \n",
    "#     return points_arrays, likelihoods_arrays, stellar_masses\n",
    "\n",
    "# num_galaxies_list = [1, 1, 1]\n",
    "# num_points_in_a_set = 2\n",
    "# peak_mass = 1e9\n",
    "# std_dev = 1e8\n",
    "# grid_size = 1000\n",
    "\n",
    "# points_arrays, likelihoods_arrays, stellar_masses = generate_points_array_likelihoods_array(num_galaxies_list, num_points_in_a_set, peak_mass, std_dev, grid_size)\n",
    "\n",
    "# # Print or use the generated points and likelihoods as needed\n",
    "\n",
    "# print(\"points = \",points_arrays,\"\\nprobabilities = \",likelihoods_arrays,\"\\nstellar mass = \",stellar_masses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
